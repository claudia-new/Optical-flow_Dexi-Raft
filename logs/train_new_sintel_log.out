nohup: ignoring input
Parameter Count: 40483149
Training with 80604 image pairs
/home/zexin/anaconda3/envs/raft/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[   100,  0.0000056]     0.6263,     0.7744,     0.8138,    11.3566, 
[   200,  0.0000072]     0.6706,     0.7986,     0.8340,    10.6717, 
[   300,  0.0000088]     0.6634,     0.7912,     0.8280,    11.3568, 
[   400,  0.0000104]     0.6662,     0.7952,     0.8319,    11.6266, 
[   500,  0.0000120]     0.6835,     0.8050,     0.8397,    10.1708, 
[   600,  0.0000136]     0.6817,     0.8026,     0.8376,     9.7177, 
[   700,  0.0000152]     0.6935,     0.8121,     0.8471,     9.1006, 
[   800,  0.0000168]     0.6701,     0.7948,     0.8305,    11.3654, 
[   900,  0.0000184]     0.6863,     0.8068,     0.8411,     9.9944, 
[  1000,  0.0000200]     0.6751,     0.7983,     0.8335,    11.5143, 
[  1100,  0.0000216]     0.6717,     0.7979,     0.8344,    10.4594, 
[  1200,  0.0000232]     0.6772,     0.8004,     0.8349,     9.8488, 
[  1300,  0.0000248]     0.6893,     0.8048,     0.8373,    11.2219, 
[  1400,  0.0000264]     0.6808,     0.7968,     0.8307,    11.2689, 
[  1500,  0.0000280]     0.6832,     0.7993,     0.8328,    11.7656, 
[  1600,  0.0000296]     0.7020,     0.8166,     0.8506,     9.1348, 
[  1700,  0.0000312]     0.7132,     0.8297,     0.8612,     9.1552, 
[  1800,  0.0000328]     0.6980,     0.8123,     0.8446,     9.6561, 
[  1900,  0.0000344]     0.7039,     0.8206,     0.8532,     9.1610, 
[  2000,  0.0000360]     0.6925,     0.8094,     0.8425,    10.4866, 
[  2100,  0.0000376]     0.7084,     0.8223,     0.8543,     8.8900, 
[  2200,  0.0000392]     0.6840,     0.8043,     0.8381,    11.3707, 
[  2300,  0.0000408]     0.6984,     0.8183,     0.8521,     9.6248, 
[  2400,  0.0000424]     0.6997,     0.8176,     0.8499,     9.3632, 
[  2500,  0.0000440]     0.6926,     0.8092,     0.8425,    10.3469, 
[  2600,  0.0000456]     0.6957,     0.8123,     0.8452,    10.5905, 
[  2700,  0.0000472]     0.6930,     0.8107,     0.8439,     9.9970, 
[  2800,  0.0000488]     0.7005,     0.8140,     0.8450,    10.7516, 
[  2900,  0.0000504]     0.7170,     0.8326,     0.8641,     7.6872, 
[  3000,  0.0000520]     0.7066,     0.8203,     0.8524,     9.1353, 
[  3100,  0.0000536]     0.6836,     0.8002,     0.8344,    12.4464, 
[  3200,  0.0000551]     0.6924,     0.8116,     0.8462,     9.0526, 
[  3300,  0.0000567]     0.7066,     0.8247,     0.8576,     8.4951, 
[  3400,  0.0000583]     0.7037,     0.8185,     0.8526,     8.7563, 
[  3500,  0.0000599]     0.7046,     0.8188,     0.8490,    10.4743, 
[  3600,  0.0000615]     0.7055,     0.8225,     0.8545,     9.4805, 
[  3700,  0.0000631]     0.7027,     0.8183,     0.8494,    12.2433, 
[  3800,  0.0000647]     0.6895,     0.8073,     0.8415,    10.0315, 
[  3900,  0.0000663]     0.7084,     0.8211,     0.8520,    10.5762, 
[  4000,  0.0000679]     0.6986,     0.8149,     0.8462,     9.1665, 
[  4100,  0.0000695]     0.6963,     0.8138,     0.8474,    10.0147, 
[  4200,  0.0000711]     0.6857,     0.8087,     0.8434,     9.1089, 
[  4300,  0.0000727]     0.7054,     0.8207,     0.8528,     9.6177, 
[  4400,  0.0000743]     0.6955,     0.8167,     0.8507,     8.8922, 
[  4500,  0.0000759]     0.6954,     0.8119,     0.8454,    10.4859, 
[  4600,  0.0000775]     0.6907,     0.8080,     0.8418,    10.3151, 
[  4700,  0.0000791]     0.6953,     0.8074,     0.8401,    11.7227, 
[  4800,  0.0000807]     0.6981,     0.8186,     0.8521,     8.1890, 
[  4900,  0.0000823]     0.6952,     0.8112,     0.8438,    10.6065, 
[  5000,  0.0000839]     0.6972,     0.8172,     0.8505,     8.8055, 
Traceback (most recent call last):
  File "train.py", line 249, in <module>
    train(args)
  File "train.py", line 196, in train
    results.update(evaluate.validate_sintel(model.module))
  File "/home/zexin/anaconda3/envs/raft/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/home/zexin/Documents/raft/evaluate.py", line 112, in validate_sintel
    flow_low, flow_pr = model(image1, image2, iters=iters, test_mode=True)
  File "/home/zexin/anaconda3/envs/raft/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "core/raft.py", line 104, in forward
    edge1 = self.dexined(image1) # Bx7xHxW
  File "/home/zexin/anaconda3/envs/raft/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "core/DexiNed/model.py", line 254, in forward
    block_cat = torch.cat(results, dim=1)  # Bx6xHxW
RuntimeError: Sizes of tensors must match except in dimension 2. Got 448 and 440 (The offending index is 0)
